from typing import List, Dict, Any
import json
import re
import hashlib
from underthesea import word_tokenize

class GeminiClient():
    def __init__(self):
        self.input_token_price = 0.1
        self.output_token_price = 0.4
        self.dollar_exchange_rate = 25000

        self.stop_words = set(
            [
                # CÃ¡c nguyÃªn Ã¢m cÃ³ dáº¥u
                "a",
                "Ã ",
                "áº£",
                "Ã£",
                "áº¡",
                "Äƒ",
                "áº¯",
                "áº±",
                "áº³",
                "áºµ",
                "áº·",
                "Ã¢",
                "áº¥",
                "áº§",
                "áº©",
                "áº«",
                "áº­",
                # CÃ¡c tá»« ná»‘i vÃ  tá»« chá»©c nÄƒng
                "báº£n_thÃ¢n",
                "bao",
                "báº¥y",
                "bá»Ÿi",
                "bá»Ÿi_vÃ¬",
                "cÃ¡c",
                "cÃ¡i",
                "cáº£",
                "cÃ ng",
                "chá»‰",
                "cho",
                "chá»©",
                "chÆ°a",
                "chuyá»‡n",
                "cá»©",
                "do",
                "dáº«u",
                "dÃ¹",
                "dÄ©",
                # Äáº¡i tá»«, giá»›i tá»« vÃ  tráº¡ng tá»« thÃ´ng dá»¥ng
                "Ä‘ang",
                "Ä‘Ã¢u",
                "Ä‘á»u",
                "Ä‘iá»u",
                "Ä‘Ã³",
                "Ä‘áº¥y",
                "Ä‘áº¿n",
                "gÃ¬",
                "ha",
                "hÆ¡i",
                "hay",
                "hÆ¡n",
                "hoáº·c",
                "háº¿t",
                # Tá»« chung, tá»« chá»‰ Ä‘á»‹nh thá»i gian, khÃ´ng gian, sá»‘ lÆ°á»£ng
                "lÃ ",
                "láº¡i",
                "lÃªn",
                "lÃºc",
                "mÃ ",
                "máº¥y",
                "má»—i",
                "má»›i",
                "nÃ y",
                "nÃªn",
                "náº¿u",
                "ná»¯a",
                "ráº¥t",
                "sau",
                "sáº½",
                "siÃªu",
                "so",
                "sá»±",
                "táº¡i",
                "theo",
                "thÃ¬",
                "thÃ´i",
                "trÃªn",
                "trong",
                "trÆ°á»›c",
                "vÃ ",
                "váº«n",
                "vÃ o",
                "váº­y",
                "vÃ¬",
                "vá»›i",
                # Má»™t sá»‘ tá»« khÃ¡c thÆ°á»ng xuáº¥t hiá»‡n khÃ´ng mang nhiá»u Ã½ nghÄ©a riÃªng
                "nhÆ°",
                "khi",
                "Ä‘áº¥y",
                "Ä‘Ã³",
            ]
        )

        self.short_words = {
            "ná»™i dung bÃ i viáº¿t": "S_ndbv",
            "nhÃ£n hÃ ng": "S_nh",
        }
        self.field_config = self.get_field_config()
        self.sentiment_mapping = self.field_config["sentiment_score"]["mapping"]

        self.reverse_mapping_by_short = {
            config["short"]: key for key, config in self.field_config.items()
        }

        self.explain_field_from_db = {
            "content_from_name": "tÃªn ngÆ°á»i Ä‘Äƒng bÃ i",
            "object_name": "TÃªn cá»§a nhÃ£n hÃ ng",
            "message": "ná»™i dung bÃ i viáº¿t",
        }
        
    def get_field_config(self):
        with open("field_config.json", "r", encoding="utf-8") as f:
            config = json.load(f)
        return config

    def get_sentiment(self, sentiment_value: float) -> str:
        for range_str, description in self.sentiment_mapping.items():
            low_str, high_str = range_str.split("->")
            low, high = float(low_str.strip()), float(high_str.strip())
            if low <= sentiment_value <= high:
                return description.strip()
        return "KhÃ´ng xÃ¡c Ä‘á»‹nh"

    def hash_content(self, content: str) -> str:
        return hashlib.sha256(content.strip().encode()).hexdigest()

    def remove_blank_space(self, text):
        return re.sub(r"\s+", " ", text).replace("\n", " ").strip()

    def clean_text(self, text):
        text = self.remove_blank_space(text)
        text = re.sub(r"([!?.,;:])\1+", r"\1", text)
        tokens = word_tokenize(text, format="text").split()
        filtered_tokens = [
            token for token in tokens if token.lower() not in self.stop_words
        ]
        cleaned_text = " ".join(filtered_tokens)
        cleaned_text = re.sub(r"((-\s*){2,})", "", text)
        return cleaned_text

    def extract_analysed_response(self, text: str):
        return (
            self.remove_blank_space(text.strip("```json\n").strip("```"))
            .replace("\n", "")
            .replace('""', '"')
        )

    def estimate_cost(self, input_usage):
        input_token = input_usage["prompt_token_count"]
        output_token = input_usage["candidates_token_count"]

        input_cost = (input_token / 1000000) * self.input_token_price
        output_cost = (output_token / 1000000) * self.output_token_price
        total_dollar = input_cost + output_cost
        total_vnd = total_dollar * self.dollar_exchange_rate
        return {
            "input_token": input_token,
            "output_token": output_token,
            "input_cost_in_dollar": f"{input_cost:.6f}",
            "output_cost_in_dollar": f"{output_cost:.6f}",
            "total_dollar": f"{total_dollar:.6f}",
            "total_vnd": f"{total_vnd:.3f}",
        }

    def get_require_input_fields(self, output_fields):
        require_input_fields = []
        for field_name in output_fields:
            field_config = self.field_config.get(field_name, None)
            if field_config is None:
                raise Exception(
                    (
                        "[ERROR][GEMINI CLIENT] field config not found: "
                        f"{field_name}"
                    )
                )
            require_input_fields += field_config["input_required"]
        return tuple(set(require_input_fields))

    def analyze_batch(
        self,
        news_items: List,
        model_name: str,
        prompt_template: str,
        module_configs: Dict[str, Any],
    ) -> List[Dict[str, Any]]:
        # build field name explain
        profession = module_configs.get("profession", "")
        require_output_fields = module_configs.get("require_output_fields", [])
        require_input_fields = self.get_require_input_fields(
            require_output_fields
        )
        field_name_explain_text = ""
        field_name_order_list = []
        for field in require_input_fields:
            field_name_explain_text += (
                "                - "
                f"{field}: {self.explain_field_from_db[field]}\n"
            )
            field_name_order_list.append(field)
        field_name_order_text = "|".join(field_name_order_list)

        # build input data in text format
        id_mapping = {}
        final_result_mapping = {}
        filtered_data_list = []
        for i, item in enumerate(news_items):
            item_keys = list(item.keys())
            missing_keys = set(require_input_fields) - set(item_keys)
            if missing_keys:
                raise Exception(f"Fields missing: {missing_keys}")

            id_int = i + 1
            id_mapping[id_int] = {
                "news_id": item["news_id"],
                "message": item["message"],
                "object_id": str(item["object_id"]),
            }
            final_result_mapping[item["news_id"]] = {
                "news_id": item["news_id"],
                "message": item["message"],
                "object_id": str(item["object_id"]),
                # "doc_type": item["doc_type"],
            }
            filtered_data_list.append(
                (
                    f"{id_int}|{item['content_from_name']}|"
                    f"{self.clean_text(item['message'])}|"
                    f"{item['object_name']}"
                )
            )
        filtered_data_text = " || ".join(filtered_data_list)

        # build output json format
        final_json_format = """
"total_post": // máº£ng chá»©a cÃ¡c object lÃ  káº¿t quáº£ Ä‘Ã£ phÃ¢n tÃ­ch cá»§a má»—i bÃ i viáº¿t
[{
    id: string // ID bÃ i viáº¿t
"""
        for field_name in require_output_fields:
            if not self.field_config[field_name]["active"]:
                continue
            final_json_format += (
                f'    {self.field_config[field_name]["short"]}: '
                f'{self.field_config[field_name]["type"]} // '
                f'{self.field_config[field_name]["definition"]}'
            )
            if self.field_config[field_name]["mapping"]:
                final_json_format += ". Káº¿t quáº£ theo quy táº¯c sau: "
                for key in self.field_config[field_name]["mapping"]:
                    final_json_format += (
                        f"{key}: "
                        f'{self.field_config[field_name]["mapping"][key]} | '
                    )
            final_json_format += "\n"
        final_json_format += "}]"

        final_prompt = self._format_prompt(
            prompt_template,
            profession,
            filtered_data_text,
            final_json_format,
            field_name_explain_text,
            field_name_order_text,
        )

        print("**********************************************")
        print(final_prompt)
        print("**********************************************")
        print()
        return final_prompt
        
    def _format_prompt(
        self,
        prompt_template: str,
        profession: str,
        filtered_data_text: str,
        json_format: str,
        field_name_explain_text: str,
        field_name_order_text: str,
    ) -> str:
        final_prompt = prompt_template.replace(
            "prompt_config_profession", profession
        )
        final_prompt = final_prompt.replace(
            "prompt_config_filtered_data_text", filtered_data_text
        )
        final_prompt = final_prompt.replace(
            "prompt_config_json_format", json_format
        )
        final_prompt = final_prompt.replace(
            "prompt_config_field_name_explain_text", field_name_explain_text
        )
        final_prompt = final_prompt.replace(
            "prompt_config_field_name_order_text", field_name_order_text
        )
        return final_prompt

    def _parse_response(
        self, response: Any, id_mapping: dict, require_output_fields: list
    ) -> Dict[str, Any]:
        final_data = []
        # TODO change package to get total used token
        # print(response.__dict__)
        # estimate_cost = self.estimate_cost()

        raw_analysed_text = self.extract_analysed_response(response.text)
        json_data = json.loads(raw_analysed_text)
        # print(">>>>>>>>>> json_data", json_data)
        total_post = json_data["total_post"]
        for item in total_post:
            result = {}
            result["news_id"] = id_mapping[int(item["id"])]["news_id"]
            result["message"] = id_mapping[int(item["id"])]["message"]
            result["object_id"] = id_mapping[int(item["id"])]["object_id"]
            result["analysis"] = {}
            result["status"] = "ok"
            try:
                for field_name in self.field_config:
                    # print(">>>>>>>>>> field_name", field_name)
                    short_field_name = self.field_config[field_name]["short"]
                    result["analysis"][field_name] = item.get(short_field_name, None)
                    if field_name in require_output_fields and result["analysis"][field_name] is None:
                        result["error"] = "Data for require_output_fields is missing"
                        result["status"] = "fail"
                # print(">>>>>>>>>> result", result)
            except Exception as err:
                result["error"] = str(err)
                result["status"] = "fail"

            final_data.append(result)
        return final_data






# ---------------- Start ----------------
news = [
    # {
    #   "news_id": "10586_11535_0_100003816695541_3538174789653043",
    #   "message": "ğŸƒÄáº¹p quÃ¡ khÃ´ng thá»ƒ cÆ°á»¡ng láº¡i sá»©c hÃºt cá»§a Quy NhÆ¡n nÃªn e lÃªn tiáº¿p cho cÃ¡c bÃ¡c combo Quy NhÆ¡n bay #Bamboo á»Ÿ káº¿t há»£p Crown Retreat Äƒn 2 bá»¯a ğŸ 4N3Ä chá»‰ #4x99k/ngÆ°á»i! ZÃ¡ nÃ y khÃ´ng Ä‘áº¹p thÃ¬ zÃ¡ nÃ o Ä‘áº¹p\n\nBao gá»“m: \nâ–ªï¸VÃ© mÃ¡y bay khá»© há»“i \nâ–ªï¸01 Ä‘Ãªm Crown Retreat - Quy NhÆ¡n triá»‡u gÃ³c sá»‘ng áº£o + Ä‚n 2 bá»¯a + Bá»ƒ BÆ¡i \nâ–ªï¸02 Ä‘Ãªm FLC Sea Tower Quy NhÆ¡n + PhÃ²ng view biá»ƒn\nâ–ªï¸TrÃ  nÆ°á»›c cf, tiá»‡n Ã­ch phÃ²ng",
    #   "object_id": 11535,
    #   "object_name": "Vincom",
    #   "content_from_name": "Huyá»n Diamond FLC Group",
    #   "page_name": "Huyá»n Diamond",
    #   "brand_id": 10586,
    #   "brand_name": "Property",
    #   "created": 1741054701
    # },
    {
      "news_id": "10586_11535_0_588844503184094_1008933217841885",
      "message": "ThÃ­ch lÃ m viá»‡c vá»›i flc group ! KhÃ´ng nhÆ° Vincom tháº¥y chÃ¡n",
      "object_id": 11535,
      "object_name": "Vincom",
      "content_from_name": "HÃ  NgÃ´",
      "page_name": "HÃ  NgÃ´",
      "brand_id": 10586,
      "brand_name": "Property",
      "created": 1741054689
    }
]

prompt_template = """
-- ÄÃ³ng vai lÃ  chuyÃªn gia phÃ¢n tÃ­ch hoáº¡t Ä‘á»™ng truyá»n thÃ´ng cá»§a cÃ¡c doanh nghiá»‡p ngÃ nh prompt_config_profession.
-- Äá»‹nh dáº¡ng dá»¯ liá»‡u dÃ¹ng cho phÃ¢n tÃ­ch:
prompt_config_field_name_explain_text
-- DÆ°á»›i Ä‘Ã¢y lÃ  cÃ¡c bÃ i bÃ¡o cáº§n phÃ¢n tÃ­ch, phÃ¢n cÃ¡ch bá»Ÿi dáº¥u '||' vÃ  má»—i bÃ i cÃ³ ID riÃªng, vá»›i Ä‘á»‹nh dáº¡ng má»—i bÃ i truyá»n vÃ o lÃ  (ID|prompt_config_field_name_order_text)
prompt_config_filtered_data_text
-- YÃªu cáº§u phÃ¢n tÃ­ch:
- PhÃ¢n tÃ­ch ká»¹ ná»™i dung cá»§a tá»«ng bÃ i bÃ¡o dá»±a vÃ o cÃ¡c trÆ°á»ng content vÃ  object.
- Má»—i bÃ i bÃ¡o Ä‘Æ°á»£c nháº­n diá»‡n bá»Ÿi ID duy nháº¥t vÃ  chá»‰ cÃ³ 1 káº¿t quáº£ phÃ¢n tÃ­ch duy nháº¥t.
- Káº¿t quáº£ phÃ¢n tÃ­ch cá»§a má»—i bÃ i bÃ¡o chá»‰ bao gá»“m cÃ¡c trÆ°á»ng sau:
prompt_config_json_format
-- Káº¿t quáº£ tráº£ vá» pháº£i theo Ä‘á»‹nh dáº¡ng JSON trong yÃªu cáº§u phÃ¢n tÃ­ch, náº±m trÃªn 1 dÃ²ng duy nháº¥t (khÃ´ng cÃ³ vÄƒn báº£n bá»• sung hay mÃ´ táº£ nÃ o khÃ¡c ngoÃ i JSON)
-- LÆ°u Ã½:
+ Äáº£m báº£o sá»‘ lÆ°á»£ng Ä‘á»‘i tÆ°á»£ng trong "total_data" báº±ng Ä‘Ãºng sá»‘ bÃ i bÃ¡o Ä‘áº§u vÃ o.
+ GiÃ¡ trá»‹ cá»§a trÆ°á»ng sc vÃ  cÃ¡c giÃ¡ trá»‹ % (náº¿u cÃ³) pháº£i náº±m trong khoáº£ng tá»« 0 Ä‘áº¿n 1.
+ Tráº£ vá» cÃ¡c káº¿t quáº£ vá»›i Ä‘á»™ tá»± tin (cháº¯n cháº¯n) trong suy luáº­n lÃ  cao nháº¥t
            """

module_configs= {
    "profession": "báº¥t Ä‘á»™ng sáº£n",
    "require_output_fields": [
        "sentiment_score",
        "tag",
        "topic",
        "relation_score",
        "value_score",
        "summary",
        "explain",
        "info_source_id",
        "predict_info_source_id",
        "language",
        "service_id",
        "attribute",
        "sub_brand",
        "spam_filter",
        "confidence_score",
    ],
}

cls_ = GeminiClient()
final_prompt = cls_.analyze_batch(news, "gemini-2", prompt_template, module_configs)

from google import genai
client = genai.Client(api_key="AIzaSyADwbsY0ZfoPv6eACowf1TXXl0RL49lTvk")
response = client.models.generate_content(
    model="gemini-2.0-flash",
    contents=final_prompt,
)
data = response.model_dump()
pretty_json = json.dumps(data, indent=4, ensure_ascii=False)
print(pretty_json)