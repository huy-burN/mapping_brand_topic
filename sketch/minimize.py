# minimize.py
import re
import emoji
import string
from typing import List

from underthesea import word_tokenize

def process_vietnamese_text(text: str) -> str:
    """Xá»­ lÃ½ text tiáº¿ng Viá»‡t vá»›i underthesea"""
    # TÃ¡ch tá»« tiáº¿ng Viá»‡t
    words = word_tokenize(text)
    return ' '.join(words)

def load_stopwords(file_path: str = 'stopwords.txt') -> List[str]:
    """Load stopwords tá»« file txt"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            stopwords = set(line.strip() for line in f)
        return stopwords
    except FileNotFoundError:
        print(f"KhÃ´ng tÃ¬m tháº¥y file {file_path}")
        return set()

def remove_emoji(text: str) -> str:
    """Loáº¡i bá» emoji tá»« text"""
    return emoji.replace_emoji(text, '')

def remove_email(text: str) -> str:
    """Loáº¡i bá» Ä‘á»‹a chá»‰ email"""
    email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}'
    return re.sub(email_pattern, '', text)

def remove_phone_numbers(text: str) -> str:
    """Loáº¡i bá» sá»‘ Ä‘iá»‡n thoáº¡i"""
    # Pattern cho sá»‘ Ä‘iá»‡n thoáº¡i Viá»‡t Nam
    phone_pattern = r'(?:(?:\+|0{0,2})84|0)[35789](?:\d{8}|\d{9})'
    return re.sub(phone_pattern, '', text)

def remove_punctuation(text: str) -> str:
    """Loáº¡i bá» dáº¥u cÃ¢u"""
    # Táº¡o translation table Ä‘á»ƒ loáº¡i bá» punctuation
    translator = str.maketrans('', '', string.punctuation)
    return text.translate(translator)

def remove_extra_spaces(text: str) -> str:
    """Loáº¡i bá» khoáº£ng tráº¯ng thá»«a"""
    return ' '.join(text.split())

def remove_urls(text: str) -> str:
    """Loáº¡i bá» URLs"""
    url_pattern = r'https?://\S+|www\.\S+'
    return re.sub(url_pattern, '', text)

def remove_special_characters(text: str) -> str:
    """Loáº¡i bá» kÃ½ tá»± Ä‘áº·c biá»‡t"""
    return re.sub(r'[^\w\s]', '', text)

def remove_numbers(text: str) -> str:
    """Loáº¡i bá» sá»‘"""
    return re.sub(r'\d+', '', text)

def remove_stopwords(text: str, stopwords: set) -> str:
    """Loáº¡i bá» stopwords"""
    words = text.split()
    filtered_words = [word for word in words if word.lower() not in stopwords]
    return ' '.join(filtered_words)

def process_text(text: str = None) -> str:
    """HÃ m xá»­ lÃ½ chÃ­nh"""
    if text is None:
        text = "ÄÃ¢y lÃ  vÄƒn báº£n máº«u cáº§n Ä‘Æ°á»£c xá»­ lÃ½"
    
    # Load stopwords
    stopwords = load_stopwords('stopwords.txt')
    
    # Chuyá»ƒn text vá» lowercase
    text = text.lower()
    
    # Thá»±c hiá»‡n cÃ¡c bÆ°á»›c xá»­ lÃ½
    text = remove_emoji(text)
    text = remove_email(text)
    text = remove_phone_numbers(text)
    text = remove_urls(text)
    text = remove_special_characters(text)
    text = remove_numbers(text)
    text = remove_punctuation(text)
    text = remove_extra_spaces(text)
    text = remove_stopwords(text, stopwords)
    
    return text

def get_minimized_result(input_text: str = None) -> str:
    """HÃ m tráº£ vá» káº¿t quáº£ Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½"""
    result = process_text(input_text)
    return result

# VÃ­ dá»¥ sá»­ dá»¥ng
if __name__ == "__main__":
    test_text = """
    Xin chÃ o! ğŸ˜Š 
    ÄÃ¢y lÃ  email cá»§a tÃ´i: example@email.com
    Sá»‘ Ä‘iá»‡n thoáº¡i: 0912345678
    Website: https://example.com
    GiÃ¡ sáº£n pháº©m lÃ  1000$ !!!
    """
    
    cleaned_text = get_minimized_result(test_text)
    print("Text gá»‘c:")
    print(test_text)
    print("\nText sau khi xá»­ lÃ½:")
    print(cleaned_text)